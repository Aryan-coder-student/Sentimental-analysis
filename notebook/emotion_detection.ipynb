{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from txt file and converting to DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = {\"text\" : [] , \"emotions\" : []}\n",
    "dataset_test = {\"text\" : [] , \"emotions\" : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseFolder = \"data\"\n",
    "#-----------------------------train-----------------\n",
    "with open(f\"{baseFolder}/train.txt\" , \"r\") as file:\n",
    "    for i in file.readlines():\n",
    "        sentence = i.split(\";\")\n",
    "        dataset_train[\"text\"].append(sentence[0])\n",
    "        target = sentence[1].split(\"\\n\")\n",
    "        dataset_train[\"emotions\"].append(target[0])\n",
    "#-----------------------test-------------------------------\n",
    "with open(f\"{baseFolder}/test.txt\" , \"r\") as file:\n",
    "    for i in file.readlines():\n",
    "        sentence = i.split(\";\")\n",
    "        dataset_test[\"text\"].append(sentence[0])\n",
    "        target = sentence[1].split(\"\\n\")\n",
    "        dataset_test[\"emotions\"].append(target[0])\n",
    "#-----------------------valid------------------------------\n",
    "with open(f\"{baseFolder}/val.txt\" , \"r\") as file:\n",
    "    for i in file.readlines():\n",
    "        sentence = i.split(\";\")\n",
    "        dataset_train[\"text\"].append(sentence[0])\n",
    "        target = sentence[1].split(\"\\n\")\n",
    "        dataset_train[\"emotions\"].append(target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "dataset_train = pd.DataFrame.from_dict(dataset_train)\n",
    "dataset_test = pd.DataFrame.from_dict(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>im having ssa examination tomorrow in the morn...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>i constantly worry about their fight against n...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>i feel its important to share this info for th...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>i truly feel that if you are passionate enough...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>i feel like i just wanna buy any cute make up ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text emotions\n",
       "0                                i didnt feel humiliated  sadness\n",
       "1      i can go from feeling so hopeless to so damned...  sadness\n",
       "2       im grabbing a minute to post i feel greedy wrong    anger\n",
       "3      i am ever feeling nostalgic about the fireplac...     love\n",
       "4                                   i am feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "17995  im having ssa examination tomorrow in the morn...  sadness\n",
       "17996  i constantly worry about their fight against n...      joy\n",
       "17997  i feel its important to share this info for th...      joy\n",
       "17998  i truly feel that if you are passionate enough...      joy\n",
       "17999  i feel like i just wanna buy any cute make up ...      joy\n",
       "\n",
       "[18000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting for data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# ps =PorterStemmer()\n",
    "def preprocess_sentence(sen):\n",
    "    doc = nlp(sen)\n",
    "    new_sen = [token.lemma_ for token in doc ]\n",
    "    return \" \".join(new_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train[\"text\"] = dataset_train[\"text\"].apply(preprocess_sentence)\n",
    "dataset_test[\"text\"] = dataset_test[\"text\"].apply(preprocess_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I do not feel humiliate</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can go from feel so hopeless to so damned ho...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I m grab a minute to post I feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I be ever feel nostalgic about the fireplace I...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I be feel grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>I m have ssa examination tomorrow in the morni...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>I constantly worry about their fight against n...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>I feel its important to share this info for th...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>I truly feel that if you be passionate enough ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>I feel like I just wanna buy any cute make up ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text emotions\n",
       "0                                I do not feel humiliate  sadness\n",
       "1      I can go from feel so hopeless to so damned ho...  sadness\n",
       "2          I m grab a minute to post I feel greedy wrong    anger\n",
       "3      I be ever feel nostalgic about the fireplace I...     love\n",
       "4                                      I be feel grouchy    anger\n",
       "...                                                  ...      ...\n",
       "17995  I m have ssa examination tomorrow in the morni...  sadness\n",
       "17996  I constantly worry about their fight against n...      joy\n",
       "17997  I feel its important to share this info for th...      joy\n",
       "17998  I truly feel that if you be passionate enough ...      joy\n",
       "17999  I feel like I just wanna buy any cute make up ...      joy\n",
       "\n",
       "[18000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dict = {value: index for index , value in enumerate(dataset_train[\"emotions\"].unique().tolist())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dict = {value: index for index , value in enumerate(dataset_test[\"emotions\"].unique().tolist())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sadness': 0, 'joy': 1, 'fear': 2, 'anger': 3, 'love': 4, 'surprise': 5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train[\"emotions\"].replace(target_dict, inplace=True)\n",
    "dataset_test[\"emotions\"].replace(target_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotions\n",
       "1    6066\n",
       "0    5216\n",
       "3    2434\n",
       "2    2149\n",
       "4    1482\n",
       "5     653\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[\"emotions\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text        0\n",
       "emotions    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text        0\n",
       "emotions    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing or feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_train[\"text\"]\n",
    "y = dataset_train[\"emotions\"].astype(int)\n",
    "X_test = dataset_test[\"text\"]\n",
    "y_test = dataset_test[\"emotions\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# import pickle\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.en import stop_words\n",
    "my_stop_words = list(stop_words.STOP_WORDS)\n",
    "cv = TfidfVectorizer(stop_words=my_stop_words)\n",
    "X = cv.fit_transform(X)\n",
    "X_test = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model Naiev Bais , Xgboost , Random Forest , Voting classifier, KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7125\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.91      0.79       581\n",
      "           1       0.67      0.99      0.80       695\n",
      "           2       0.91      0.38      0.54       224\n",
      "           3       0.96      0.41      0.57       275\n",
      "           4       0.93      0.09      0.16       159\n",
      "           5       1.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.71      2000\n",
      "   macro avg       0.86      0.46      0.48      2000\n",
      "weighted avg       0.78      0.71      0.66      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X, y)\n",
    "\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report = classification_report(y_test, y_pred,zero_division=1)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.837\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88       581\n",
      "           1       0.82      0.90      0.86       695\n",
      "           2       0.90      0.76      0.82       224\n",
      "           3       0.85      0.87      0.86       275\n",
      "           4       0.70      0.63      0.66       159\n",
      "           5       0.53      0.71      0.61        66\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.79      0.79      0.78      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=300, learning_rate=1.0,max_depth=5, random_state=0)\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report = classification_report(y_test, y_pred,zero_division=1)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.862\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       581\n",
      "           1       0.86      0.92      0.89       695\n",
      "           2       0.83      0.86      0.84       224\n",
      "           3       0.90      0.84      0.87       275\n",
      "           4       0.77      0.64      0.70       159\n",
      "           5       0.65      0.59      0.62        66\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.82      0.79      0.80      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "rf_classifier.fit(X, y)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "report = classification_report(y_test, y_pred,zero_division=1)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7795\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.81       581\n",
      "           1       0.80      0.84      0.82       695\n",
      "           2       0.84      0.71      0.77       224\n",
      "           3       0.79      0.71      0.75       275\n",
      "           4       0.69      0.50      0.58       159\n",
      "           5       0.68      0.48      0.57        66\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.76      0.69      0.72      2000\n",
      "weighted avg       0.78      0.78      0.77      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X, y)\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "report = classification_report(y_test, y_pred, zero_division=1)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.854\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       581\n",
      "           1       0.84      0.91      0.87       695\n",
      "           2       0.90      0.76      0.82       224\n",
      "           3       0.85      0.87      0.86       275\n",
      "           4       0.77      0.65      0.71       159\n",
      "           5       0.54      0.76      0.63        66\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.80      0.81      0.80      2000\n",
      "weighted avg       0.86      0.85      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vc = VotingClassifier(estimators = [(\"xg\" ,clf) , (\"rf\", rf_classifier) ] , voting = \"soft\")\n",
    "vc = vc.fit(X , y)\n",
    "y_pred = vc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "report = classification_report(y_test, y_pred,zero_division=1)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"emotions.pkl\", \"wb\") as f:\n",
    "    pickle.dump((rf_classifier, cv), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model RNN , GRU , LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torch import optim\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>Converting to Tensor for training model </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X.toarray()).to(torch.float32).to(device)\n",
    "X_train_tensor_pad = pad_sequence(X_train_tensor, batch_first=True, padding_value=0)\n",
    "X_test_tensor  = torch.from_numpy(X_test.toarray()).to(device)\n",
    "X_test_tensor_pad = pad_sequence(X_test_tensor, batch_first=True, padding_value=0)\n",
    "y_train_tensor = torch.Tensor(y.tolist()).to(device)\n",
    "y_test_tensor = torch.Tensor(y_test.tolist()).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12516"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor_pad.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u> Creating rnn , lstm and gru model </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnnModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_mood=6):\n",
    "        super(rnnModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size*2, num_layers=2 , batch_first = True)\n",
    "        self.model = nn.Sequential(\n",
    "             nn.Linear(hidden_size * 2, hidden_size),  # multiplied by 4 due to bidirectional LSTM\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(hidden_size // 2, num_mood),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        output_rnn, _ = self.rnn(x)\n",
    "        output = self.model(output_rnn)  \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_mood=6):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size*2, num_layers=2, batch_first=True, bidirectional=False)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),  # multiplied by 4 due to bidirectional LSTM\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(hidden_size // 2, num_mood),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        output_rnn, _ = self.lstm(x)\n",
    "        output = self.model(output_rnn)  \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_mood=6):\n",
    "        super(BiGRU, self).__init__()\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size*2, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 4, hidden_size),  # multiplied by 4 due to bidirectional GRU\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(hidden_size // 2, num_mood),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output_rnn, _ = self.gru(x)\n",
    "        output = self.model(output_rnn)  \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor_pad, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor_pad, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17999"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "hidden_size = 128 \n",
    "vocab_size = len(cv.vocabulary_)\n",
    "model = BiGRU(X_train_tensor.shape[1], hidden_size = hidden_size).to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiGRU(\n",
       "  (gru): GRU(12516, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.25, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.25, inplace=False)\n",
       "    (6): Linear(in_features=64, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchmetrics import Accuracy\n",
    "accuracy_metric = Accuracy(task=\"multiclass\" , num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor_pad = X_test_tensor_pad.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 1.2233, Test Loss: 0.6915, Test Acc: 0.7460\n",
      "Epoch 2/5, Train Loss: 0.4840, Test Loss: 0.4992, Test Acc: 0.8230\n",
      "Epoch 3/5, Train Loss: 0.2453, Test Loss: 0.5495, Test Acc: 0.8320\n",
      "Epoch 4/5, Train Loss: 0.1637, Test Loss: 0.5362, Test Acc: 0.8275\n",
      "Epoch 5/5, Train Loss: 0.1320, Test Loss: 0.6262, Test Acc: 0.8230\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        batch_y = batch_y.long()\n",
    "        loss = loss_func(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        # nn.utils.clip_grad_norm_(model.parameters(),0.7)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test_tensor_pad)\n",
    "        probabilities = F.softmax(y_pred, dim=1)\n",
    "        predicted_classes = torch.argmax(probabilities, dim=1)\n",
    "        test_loss = loss_func(y_pred, y_test_tensor.long())\n",
    "        test_acc = torch.sum(predicted_classes == y_test_tensor).item() / len(y_test_tensor)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {avg_loss:.4f}, Test Loss: {test_loss.item():.4f}, Test Acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -2.5074,  -8.0761,   6.0209,  -5.4037,  -7.4044,   2.8774],\n",
      "        [ -4.7107,  -8.0258,   4.8750,  -1.1334,  -5.8353,   4.2952],\n",
      "        [  3.6265,  -9.6321,  -3.9772, -10.9237,  -7.4823,  12.5051],\n",
      "        ...,\n",
      "        [ 14.5118,  -0.8635,  -7.9909, -24.9178,  -8.4342,   2.3578],\n",
      "        [ 14.3551,  -0.2435,  -7.9499, -25.1739,  -8.3177,   1.7826],\n",
      "        [ -2.1728,   8.1011, -13.4091, -13.8454,   7.9622,  -7.5289]])\n"
     ]
    }
   ],
   "source": [
    "  print(y_pred.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
